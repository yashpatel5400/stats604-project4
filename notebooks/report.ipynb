{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f75b127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "if \"data\" not in os.listdir(\".\"):\n",
    "    os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5a06a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) # ignore FutureWarnings from pd\n",
    "\n",
    "import datetime\n",
    "import pickle\n",
    "import logging\n",
    "import pytz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from raw_data import wunderground_download\n",
    "import predictor.utils as utils\n",
    "from predictor.models.predictor_zeros import ZerosPredictor\n",
    "from predictor.models.unique import ArimaPredictor\n",
    "from predictor.models.unique import HistoricAveragePredictor\n",
    "from predictor.models.seamus import BasicOLSPredictor\n",
    "from predictor.models.seamus import LassoPredictor\n",
    "from predictor.models.seamus import GBTPredictor\n",
    "from predictor.models.vinod import PrevDayHistoricalPredictor\n",
    "from predictor.models.vinod import MetaPredictor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from predictor.models.predictor_scaffold import Predictor\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d091e6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_full_eval_data(start_eval_date, eval_len, wunderground_lookback):\n",
    "    \"\"\"Prepares data for evaluation for a window of [start_eval_date, start_eval_date + eval_len] \n",
    "    where eval_len is to be specified as the number of days. Note that the data returned from this\n",
    "    is NOT the data that is to be used for evaluation, i.e. each eval_day must be separated after\n",
    "    this initial bulk fetch (using get_eval_task)\n",
    "    \n",
    "    args:\n",
    "        start_eval_date: (datetime.datetime) day of first *evaluation*, i.e. first day where predictions are *made*\n",
    "            Note: that EACH eval day is evaluated for 5 days forward!\n",
    "        eval_len: how many eval days to include\n",
    "        wunderground_lookback: how far (in days) *before the first eval day* to extend the Wunderground data\n",
    "            Note: data scraping will take time proportional to this number\n",
    "    \"\"\"\n",
    "    noaa = utils.load_processed_data_src(\"noaa\")\n",
    "    full_eval_data = {}\n",
    "    for station in utils.stations:\n",
    "        full_eval_data[station] = {}\n",
    "        full_eval_data[station][\"noaa\"] = noaa[station]\n",
    "        full_eval_data[station][\"wunderground\"] = wunderground_download.fetch_wunderground_pd(\n",
    "            station, start_eval_date, eval_len, wunderground_lookback)\n",
    "    return full_eval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8185de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_station_eval_task(full_eval_data, prediction_date, station):\n",
    "    full_noaa = full_eval_data[station][\"noaa\"]\n",
    "    full_wunderground = full_eval_data[station][\"wunderground\"]\n",
    "\n",
    "    est = pytz.timezone('US/Eastern')\n",
    "    strict_cutoff = est.localize(prediction_date.replace(hour=12)) # all the predictions are going to be made noon EST\n",
    "\n",
    "    local_timezone = pytz.timezone(utils.fetch_timezone(station))\n",
    "    full_wunderground['date_col'] = pd.to_datetime(full_wunderground.index).tz_convert(local_timezone).date\n",
    "    \n",
    "    # cutoff_side = 0: < \"prediction cutoff\" -- used to construct our dataset\n",
    "    # cutoff_side = 1: > \"prediction cutoff\" -- used to construct the evaluation target\n",
    "    for cutoff_side in range(2):\n",
    "        if cutoff_side == 0:\n",
    "            dataset_view = full_wunderground[full_wunderground.index < strict_cutoff]\n",
    "        else:\n",
    "            dataset_view = full_wunderground[full_wunderground.index >= strict_cutoff]\n",
    "\n",
    "        # Wunderground returns granular (hourly) data points, but we only want daily for prediction: this coarsens the dataset\n",
    "        # TODO: time permitting, could remove this since it is a bit of a duplicate from process_wunderground\n",
    "        aggregated_columns = [\"temp\", \"wspd\", \"pressure\", \"heat_index\", 'dewPt']\n",
    "        maxes = dataset_view.groupby(['date_col'], sort=False)[aggregated_columns].max().set_axis([f\"{column}_max\" for column in aggregated_columns], axis=1, inplace=False).set_index(dataset_view['date_col'].unique())\n",
    "        means = dataset_view.groupby(['date_col'], sort=False)[aggregated_columns].mean().set_axis([f\"{column}_mean\" for column in aggregated_columns], axis=1, inplace=False).set_index(dataset_view['date_col'].unique())\n",
    "        mins  = dataset_view.groupby(['date_col'], sort=False)[aggregated_columns].min().set_axis([f\"{column}_min\" for column in aggregated_columns], axis=1, inplace=False).set_index(dataset_view['date_col'].unique())\n",
    "        wind_dir = dataset_view.groupby(['date_col'], sort=False)['wdir_cardinal'].agg(\n",
    "            lambda x: pd.Series.mode(x)[0]).astype(\"category\").to_frame(\"wdir_mode\").set_index(dataset_view['date_col'].unique())\n",
    "        aggregated_wunderground = pd.concat((mins, means, maxes, wind_dir), axis=1)\n",
    "\n",
    "        if cutoff_side == 0:\n",
    "            cut_wunderground = aggregated_wunderground.drop(aggregated_wunderground.index[0], axis=0) # first row is often partial day based on the time zone\n",
    "        else:\n",
    "            evaluation_data = aggregated_wunderground\n",
    "\n",
    "    noaa_cutoff_len = 3\n",
    "    noaa_cutoff = prediction_date - datetime.timedelta(days=noaa_cutoff_len)\n",
    "    cut_noaa = full_noaa.iloc[full_noaa.index < noaa_cutoff]\n",
    "    \n",
    "    forecast_horizon = 5\n",
    "    prediction_window = [prediction_date + datetime.timedelta(days=forecast_day) for forecast_day in range(1, forecast_horizon + 1)]\n",
    "    prediction_targets_df = evaluation_data.loc[prediction_window]\n",
    "    target = []\n",
    "    for i in range(len(prediction_targets_df)):\n",
    "        target.append(prediction_targets_df[\"temp_min\"][i])\n",
    "        target.append(prediction_targets_df[\"temp_mean\"][i])\n",
    "        target.append(prediction_targets_df[\"temp_max\"][i])\n",
    "    target = np.array(target)\n",
    "\n",
    "    data = {\n",
    "        \"noaa\": cut_noaa,\n",
    "        \"wunderground\": cut_wunderground,\n",
    "    }\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9501f1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_task(full_eval_data, prediction_date):\n",
    "    full_data = {}\n",
    "    full_target = []\n",
    "    for station in utils.stations:\n",
    "        data, target = get_station_eval_task(full_eval_data, prediction_date, station)\n",
    "        full_data[station] = data\n",
    "        full_target.append(target.flatten())\n",
    "    full_target = np.array(full_target).flatten()\n",
    "    return full_data, full_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fba8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_single_window(start_eval_date, eval_len, wunderground_lookback, model):\n",
    "    \"\"\"Runs an evaluation for a window of [start_eval_date, start_eval_date + eval_len] \n",
    "    where eval_len is to be specified as the number of days\n",
    "    \n",
    "    args:\n",
    "        start_eval_date: (datetime.datetime) day of first *evaluation*, i.e. first day where predictions are *made*\n",
    "            Note: that EACH eval day is evaluated for 5 days forward!\n",
    "        eval_len: how many eval days to include\n",
    "        wunderground_lookback: how far (in days) *before the first eval day* to extend the Wunderground data\n",
    "            Note: data scraping will take time proportional to this number\n",
    "    \"\"\"\n",
    "    full_eval_data = prepare_full_eval_data(start_eval_date, eval_len, wunderground_lookback)\n",
    "    \n",
    "    mses = []\n",
    "    for day_offset in range(eval_len):\n",
    "        prediction_date = start_eval_date + datetime.timedelta(days=day_offset)\n",
    "        eval_data, eval_target = get_eval_task(full_eval_data, prediction_date)\n",
    "        \n",
    "        predictions = model.predict(eval_data)\n",
    "        mse = (np.square(eval_target - predictions)).mean()\n",
    "        print(mse)\n",
    "        mses.append(mse)\n",
    "    return mses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0718d2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model):\n",
    "    \"\"\"Runs evaluations for a windows from 11/30 - 12/10 for multiple years (default: 10 years) \n",
    "    using the specified model as the predictor. Returns MSEs as a 20 x 15 matrix, with each station a row\n",
    "    across the 10 years with the year as the key of a dict, i.e.:\n",
    "    \n",
    "    {\n",
    "        2012: [MSEs],\n",
    "        2013: [MSEs],\n",
    "        ...\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    start_year = 2019\n",
    "    num_years = 1\n",
    "    mses_per_year = {}\n",
    "    wunderground_lookback = 365 # how many days back to return of wunderground data\n",
    "    eval_len = 10 # how many days we running evaluation for\n",
    "    \n",
    "    for year in range(start_year, start_year + num_years):\n",
    "        start_eval_str = f\"{year}-11-30\" # when eval period starts (must follow %Y-%m-%d format)\n",
    "        start_eval_date = datetime.datetime.strptime(start_eval_str, \"%Y-%m-%d\") \n",
    "        mses_per_year[year] = eval_single_window(start_eval_date, eval_len, wunderground_lookback, model)\n",
    "    return mses_per_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60971341",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_features = ['temp_min', 'wspd_min', 'pressure_min', 'heat_index_min', 'dewPt_min',\n",
    "   'temp_mean', 'wspd_mean', 'pressure_mean', 'heat_index_mean',\n",
    "   'dewPt_mean', 'temp_max', 'wspd_max', 'pressure_max', 'heat_index_max',\n",
    "   'dewPt_max', 'wdir_mode']\n",
    "reg = MultiOutputRegressor(GradientBoostingRegressor(n_estimators=20,))\n",
    "window_size = 3\n",
    "model = MetaPredictor(reg, window_size, keep_features)\n",
    "\n",
    "eval_mses = eval(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d99ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eval_mses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Prediction\n",
    "By Yash Patel, Vinod Raman, Seamus Somerstep, and Unique Subedi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sources and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we discuss simple, computationally-efficient baseline prediction models that enable us to evaluate the performance of more sophisticated models that we introduce in the upcoming sections. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Previous Day Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first baseline model, termed the Previous Day Predictor, exploits the idea that for every station, today's minimum, average, and maximum tempertures are good estimates for the minimum, average, and maximum temperates for *each* of the next five days. To this end, the Previous Day Predictor predicts for each station, for each of the next five days, today's minimum, average, and maximum temperture as the respective minimum, average, and maximum temperature for that day. That is, for each station, the Previous Day Predictor outputs a vector of 15 values consisting of today's minimum, average, and maximum temperatures repeated five times in a row. The model class below formalizes this idea in code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrevDayPredictor(Predictor):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def predict(self, data):\n",
    "        stations_data = [list(data[station][\"wunderground\"].iloc[-1][[\"temp_min\",\"temp_mean\",\"temp_max\"]].values) * 5 for station in utils.stations]\n",
    "        stations_data = np.array(stations_data).flatten()\n",
    "        return stations_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that wunderground data is used to compute \"today's\" minimum, average, and maximum temperature since the NOAA dataset lags by a c ouple days. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Historical Average Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted Average Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression-Based Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordinary Least Squares Regression (OLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multilayer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
