{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f75b127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "if \"data\" not in os.listdir(\".\"):\n",
    "    os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e5a06a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) # ignore FutureWarnings from pd\n",
    "\n",
    "import datetime\n",
    "import pickle\n",
    "import logging\n",
    "import pytz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from raw_data import wunderground_download\n",
    "import predictor.utils as utils\n",
    "from predictor.models.predictor_zeros import ZerosPredictor\n",
    "from predictor.models.unique import ArimaPredictor\n",
    "from predictor.models.unique import HistoricAveragePredictor\n",
    "from predictor.models.seamus import BasicOLSPredictor\n",
    "from predictor.models.seamus import LassoPredictor\n",
    "from predictor.models.seamus import GBTPredictor\n",
    "from predictor.models.vinod import PrevDayHistoricalPredictor\n",
    "from predictor.models.vinod import MetaPredictor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d091e6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_full_eval_data(start_eval_date, eval_len, wunderground_lookback):\n",
    "    \"\"\"Prepares data for evaluation for a window of [start_eval_date, start_eval_date + eval_len] \n",
    "    where eval_len is to be specified as the number of days. Note that the data returned from this\n",
    "    is NOT the data that is to be used for evaluation, i.e. each eval_day must be separated after\n",
    "    this initial bulk fetch (using get_eval_task)\n",
    "    \n",
    "    args:\n",
    "        start_eval_date: (datetime.datetime) day of first *evaluation*, i.e. first day where predictions are *made*\n",
    "            Note: that EACH eval day is evaluated for 5 days forward!\n",
    "        eval_len: how many eval days to include\n",
    "        wunderground_lookback: how far (in days) *before the first eval day* to extend the Wunderground data\n",
    "            Note: data scraping will take time proportional to this number\n",
    "    \"\"\"\n",
    "    noaa = utils.load_processed_data_src(\"noaa\")\n",
    "    full_eval_data = {}\n",
    "    for station in utils.stations:\n",
    "        full_eval_data[station] = {}\n",
    "        full_eval_data[station][\"noaa\"] = noaa[station]\n",
    "        full_eval_data[station][\"wunderground\"] = wunderground_download.fetch_wunderground_pd(\n",
    "            station, start_eval_date, eval_len, wunderground_lookback)\n",
    "    return full_eval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d8185de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_station_eval_task(full_eval_data, prediction_date, station):\n",
    "    full_noaa = full_eval_data[station][\"noaa\"]\n",
    "    full_wunderground = full_eval_data[station][\"wunderground\"]\n",
    "\n",
    "    est = pytz.timezone('US/Eastern')\n",
    "    strict_cutoff = est.localize(prediction_date.replace(hour=12)) # all the predictions are going to be made noon EST\n",
    "\n",
    "    local_timezone = pytz.timezone(utils.fetch_timezone(station))\n",
    "    full_wunderground['date_col'] = pd.to_datetime(full_wunderground.index).tz_convert(local_timezone).date\n",
    "    \n",
    "    # cutoff_side = 0: < \"prediction cutoff\" -- used to construct our dataset\n",
    "    # cutoff_side = 1: > \"prediction cutoff\" -- used to construct the evaluation target\n",
    "    for cutoff_side in range(2):\n",
    "        if cutoff_side == 0:\n",
    "            dataset_view = full_wunderground[full_wunderground.index < strict_cutoff]\n",
    "        else:\n",
    "            dataset_view = full_wunderground[full_wunderground.index >= strict_cutoff]\n",
    "\n",
    "        # Wunderground returns granular (hourly) data points, but we only want daily for prediction: this coarsens the dataset\n",
    "        # TODO: time permitting, could remove this since it is a bit of a duplicate from process_wunderground\n",
    "        aggregated_columns = [\"temp\", \"wspd\", \"pressure\", \"heat_index\", 'dewPt']\n",
    "        maxes = dataset_view.groupby(['date_col'], sort=False)[aggregated_columns].max().set_axis([f\"{column}_max\" for column in aggregated_columns], axis=1, inplace=False).set_index(dataset_view['date_col'].unique())\n",
    "        means = dataset_view.groupby(['date_col'], sort=False)[aggregated_columns].mean().set_axis([f\"{column}_mean\" for column in aggregated_columns], axis=1, inplace=False).set_index(dataset_view['date_col'].unique())\n",
    "        mins  = dataset_view.groupby(['date_col'], sort=False)[aggregated_columns].min().set_axis([f\"{column}_min\" for column in aggregated_columns], axis=1, inplace=False).set_index(dataset_view['date_col'].unique())\n",
    "        wind_dir = dataset_view.groupby(['date_col'], sort=False)['wdir_cardinal'].agg(\n",
    "            lambda x: pd.Series.mode(x)[0]).astype(\"category\").to_frame(\"wdir_mode\").set_index(dataset_view['date_col'].unique())\n",
    "        aggregated_wunderground = pd.concat((mins, means, maxes, wind_dir), axis=1)\n",
    "\n",
    "        if cutoff_side == 0:\n",
    "            cut_wunderground = aggregated_wunderground.drop(aggregated_wunderground.index[0], axis=0) # first row is often partial day based on the time zone\n",
    "        else:\n",
    "            evaluation_data = aggregated_wunderground\n",
    "\n",
    "    noaa_cutoff_len = 3\n",
    "    noaa_cutoff = prediction_date - datetime.timedelta(days=noaa_cutoff_len)\n",
    "    cut_noaa = full_noaa.iloc[full_noaa.index < noaa_cutoff]\n",
    "    \n",
    "    forecast_horizon = 5\n",
    "    prediction_window = [prediction_date + datetime.timedelta(days=forecast_day) for forecast_day in range(1, forecast_horizon + 1)]\n",
    "    prediction_targets_df = evaluation_data.loc[prediction_window]\n",
    "    target = []\n",
    "    for i in range(len(prediction_targets_df)):\n",
    "        target.append(prediction_targets_df[\"temp_min\"][i])\n",
    "        target.append(prediction_targets_df[\"temp_mean\"][i])\n",
    "        target.append(prediction_targets_df[\"temp_max\"][i])\n",
    "    target = np.array(target)\n",
    "\n",
    "    data = {\n",
    "        \"noaa\": cut_noaa,\n",
    "        \"wunderground\": cut_wunderground,\n",
    "    }\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9501f1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_task(full_eval_data, prediction_date):\n",
    "    full_data = {}\n",
    "    full_target = []\n",
    "    for station in utils.stations:\n",
    "        data, target = get_station_eval_task(full_eval_data, prediction_date, station)\n",
    "        full_data[station] = data\n",
    "        full_target.append(target.flatten())\n",
    "    full_target = np.array(full_target).flatten()\n",
    "    return full_data, full_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36fba8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_single_window(start_eval_date, eval_len, wunderground_lookback, model):\n",
    "    \"\"\"Runs an evaluation for a window of [start_eval_date, start_eval_date + eval_len] \n",
    "    where eval_len is to be specified as the number of days\n",
    "    \n",
    "    args:\n",
    "        start_eval_date: (datetime.datetime) day of first *evaluation*, i.e. first day where predictions are *made*\n",
    "            Note: that EACH eval day is evaluated for 5 days forward!\n",
    "        eval_len: how many eval days to include\n",
    "        wunderground_lookback: how far (in days) *before the first eval day* to extend the Wunderground data\n",
    "            Note: data scraping will take time proportional to this number\n",
    "    \"\"\"\n",
    "    full_eval_data = prepare_full_eval_data(start_eval_date, eval_len, wunderground_lookback)\n",
    "    \n",
    "    mses = []\n",
    "    for day_offset in range(eval_len):\n",
    "        prediction_date = start_eval_date + datetime.timedelta(days=day_offset)\n",
    "        eval_data, eval_target = get_eval_task(full_eval_data, prediction_date)\n",
    "        \n",
    "        predictions = model.predict(eval_data)\n",
    "        mse = (np.square(eval_target - predictions)).mean()\n",
    "        print(mse)\n",
    "        mses.append(mse)\n",
    "    return mses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0718d2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model):\n",
    "    \"\"\"Runs evaluations for a windows from 11/30 - 12/10 for multiple years (default: 10 years) \n",
    "    using the specified model as the predictor. Returns MSEs as a 20 x 15 matrix, with each station a row\n",
    "    across the 10 years with the year as the key of a dict, i.e.:\n",
    "    \n",
    "    {\n",
    "        2012: [MSEs],\n",
    "        2013: [MSEs],\n",
    "        ...\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    start_year = 2019\n",
    "    num_years = 1\n",
    "    mses_per_year = {}\n",
    "    wunderground_lookback = 365 # how many days back to return of wunderground data\n",
    "    eval_len = 10 # how many days we running evaluation for\n",
    "    \n",
    "    for year in range(start_year, start_year + num_years):\n",
    "        start_eval_str = f\"{year}-11-30\" # when eval period starts (must follow %Y-%m-%d format)\n",
    "        start_eval_date = datetime.datetime.strptime(start_eval_str, \"%Y-%m-%d\") \n",
    "        mses_per_year[year] = eval_single_window(start_eval_date, eval_len, wunderground_lookback, model)\n",
    "    return mses_per_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60971341",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_features = ['temp_min', 'wspd_min', 'pressure_min', 'heat_index_min', 'dewPt_min',\n",
    "   'temp_mean', 'wspd_mean', 'pressure_mean', 'heat_index_mean',\n",
    "   'dewPt_mean', 'temp_max', 'wspd_max', 'pressure_max', 'heat_index_max',\n",
    "   'dewPt_max', 'wdir_mode']\n",
    "reg = MultiOutputRegressor(GradientBoostingRegressor(n_estimators=20,))\n",
    "window_size = 3\n",
    "model = MetaPredictor(reg, window_size, keep_features)\n",
    "\n",
    "eval_mses = eval(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64d99ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2019: [40.04382824416481, 47.37988480304823, 35.25114797198315, 31.604587502325693, 38.1203304066177, 51.138434325225546, 78.37847184623607, 76.87509207046875, 75.00575597788894, 68.7673802943394]}\n"
     ]
    }
   ],
   "source": [
    "print(eval_mses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('bliss')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "97f4452dae6bdba237fd800176b85e526041526e1433dfb6b82689f83ea463b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
